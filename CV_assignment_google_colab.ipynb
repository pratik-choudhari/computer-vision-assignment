{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "CV_assignment_google_colab.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh3pA2TE_WLR",
        "outputId": "5d3414d1-93e5-4bb8-d972-72b43736759a"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import emoji\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcwGKkbTEGzs",
        "outputId": "aa066994-47b2-446c-eeac-8b8c2973f90b"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.0\n",
            "Running on TPU  ['10.11.101.234:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.11.101.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.11.101.234:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.11.101.234:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.11.101.234:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QNJCweF_WLg"
      },
      "source": [
        "vocab_size=10000\n",
        "maxlen= 50\n",
        "output_dim = 32\n",
        "\n",
        "def read_file(name):\n",
        "  \"\"\"\n",
        "  Reads csv file and keeps row with acceptables class values\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(name)\n",
        "  df = df[df['Class'].isin(['0','1'])]\n",
        "  return df.dropna()\n",
        "\n",
        "def split_data(x, y):\n",
        "  \"\"\"\n",
        "  Split into train test\n",
        "  \"\"\"\n",
        "  y_data = np.array([int(i) for i in y])\n",
        "  return train_test_split(x_data, y_data, test_size = 0.3, random_state=42)\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "all_words = []\n",
        "emoji_reg = emoji.get_emoji_regexp()\n",
        "def sanitize_text(text):\n",
        "  \"\"\"\n",
        "  Cleans tweet data by removing mentions, http links and retweet tags\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # replace retweet tags\n",
        "      text = re.sub('^(RT @\\w+)', '', text)\n",
        "      # replace website URLs\n",
        "      text = re.sub('(https://t\\.co)([A-Za-z0-9./]+)', '', text)\n",
        "      # replace mentions\n",
        "      text = re.sub('(@\\w+)', '', text)\n",
        "      # replace emojis\n",
        "      text = emoji_reg.sub(u'', text)\n",
        "\n",
        "      text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "      text_rc = re.sub('[0-9]+', '', text_lc)\n",
        "      tokens = word_tokenize(text_rc)\n",
        "      text = [ps.stem(word) for word in tokens if word not in stopword]\n",
        "      all_words.extend(text)\n",
        "  except Exception as e:\n",
        "      print(e)\n",
        "  return text\n",
        "\n",
        "def clean_data(df):\n",
        "  \"\"\"\n",
        "  Creates new column with cleaned text and keeps only top 10000 most frequent words\n",
        "  \"\"\"\n",
        "  df['cleaned_text'] = df['Text'].apply(sanitize_text)\n",
        "  keys = dict(collections.Counter(all_words).most_common(vocab_size)).keys()\n",
        "\n",
        "  def keep_top(text):\n",
        "    text = [i for i in text if i in keys]\n",
        "    return \" \".join(text)\n",
        "\n",
        "\n",
        "  df['cleaned_text'] = df['cleaned_text'].apply(keep_top)\n",
        "  return df\n",
        "\n",
        "def encode_data(df, x):\n",
        "  \"\"\"\n",
        "  Integer encodes words in text to prepare data for embeddings\n",
        "  \"\"\"\n",
        "  encod_corp=[]\n",
        "  for i,doc in enumerate(df[x].tolist()):\n",
        "      encod_corp.append(one_hot(doc,vocab_size))\n",
        "  pad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='pre',value=0.0)\n",
        "  return pad_corp\n",
        "\n",
        "def create_model():\n",
        "  \"\"\"\n",
        "  Create model as mentioned in image\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(layers.Input(shape=(maxlen,), dtype='float64'))\n",
        "  model.add(layers.Embedding(input_dim=vocab_size,output_dim=output_dim,input_length=maxlen))\n",
        "\n",
        "  model.add(layers.Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(50,32)))\n",
        "  model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "  model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True)))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Bidirectional(layers.LSTM(256)))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  adam = Adam(learning_rate=0.001)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def run_and_evaluate(model, epochs=1, batchsize=64):\n",
        "  \"\"\"\n",
        "  trains model and evaluates on given metrics\n",
        "  \"\"\"\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batchsize, verbose=1)\n",
        "  print('-'*40)\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = [round(i[0]) for i in y_pred]\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy score: {acc}\")\n",
        "  mcc = matthews_corrcoef(y_test, y_pred)\n",
        "  print(f\"Maththews correlation coefficient: {mcc}\")\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  print(f\"Confusion Matrix:\\n{cm}\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKtEWRcx_WLh"
      },
      "source": [
        "df = read_file(\"Colab Notebooks/data/CVAssignmentDataset.csv\")\n",
        "df_cleaned = clean_data(df)\n",
        "x_data = encode_data(df_cleaned, 'cleaned_text')\n",
        "x_train, x_test, y_train, y_test = split_data(x_data, df_cleaned['Class'].tolist())\n",
        "model = create_model()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMVy9poA_WLm",
        "outputId": "60d0f57d-2d0e-4ff7-e796-02f228e29683"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 50, 32)            320000    \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 50, 32)            1056      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 25, 32)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 25, 512)           591872    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 25, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,538,465\n",
            "Trainable params: 3,538,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RJUXjnJ_WLp",
        "outputId": "edd43018-27ba-4371-eb98-3e49aa786c1b"
      },
      "source": [
        "model = create_model()\n",
        "run_and_evaluate(model, 15, 128)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "473/473 [==============================] - 82s 160ms/step - loss: 0.6320 - accuracy: 0.6098\n",
            "Epoch 2/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.4911 - accuracy: 0.7590\n",
            "Epoch 3/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.4609 - accuracy: 0.7750\n",
            "Epoch 4/15\n",
            "473/473 [==============================] - 76s 160ms/step - loss: 0.4345 - accuracy: 0.7906\n",
            "Epoch 5/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.4213 - accuracy: 0.7964\n",
            "Epoch 6/15\n",
            "473/473 [==============================] - 76s 160ms/step - loss: 0.4041 - accuracy: 0.8071\n",
            "Epoch 7/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.3901 - accuracy: 0.8161\n",
            "Epoch 8/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.3792 - accuracy: 0.8166\n",
            "Epoch 9/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.3602 - accuracy: 0.8259\n",
            "Epoch 10/15\n",
            "473/473 [==============================] - 76s 160ms/step - loss: 0.3393 - accuracy: 0.8365\n",
            "Epoch 11/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.3210 - accuracy: 0.8465\n",
            "Epoch 12/15\n",
            "473/473 [==============================] - 76s 160ms/step - loss: 0.2986 - accuracy: 0.8548\n",
            "Epoch 13/15\n",
            "473/473 [==============================] - 76s 160ms/step - loss: 0.2753 - accuracy: 0.8668\n",
            "Epoch 14/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.2595 - accuracy: 0.8739\n",
            "Epoch 15/15\n",
            "473/473 [==============================] - 76s 161ms/step - loss: 0.2436 - accuracy: 0.8789\n",
            "----------------------------------------\n",
            "Accuracy score: 0.7103091988588172\n",
            "Maththews correlation coefficient: 0.4210338900381974\n",
            "Confusion Matrix:\n",
            "[[10171  3107]\n",
            " [ 4407  8253]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}