{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Bipolar_submission_1.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh3pA2TE_WLR",
        "outputId": "b33b3ab7-968b-46b4-a3b3-6488d5a3a68b"
      },
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk import word_tokenize\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, matthews_corrcoef\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My Drive\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/My Drive\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcwGKkbTEGzs",
        "outputId": "06750a2f-d010-47b4-b826-c7e989d74fef"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.0\n",
            "Running on TPU  ['10.5.33.106:8470']\n",
            "WARNING:tensorflow:TPU system grpc://10.5.33.106:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.5.33.106:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.5.33.106:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.5.33.106:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QNJCweF_WLg"
      },
      "source": [
        "vocab_size=10000\n",
        "maxlen= 50\n",
        "output_dim = 32\n",
        "\n",
        "def read_file(name):\n",
        "  \"\"\"\n",
        "  Reads csv file and keeps row with acceptables class values\n",
        "  \"\"\"\n",
        "  df = pd.read_csv(name)\n",
        "  df = df[df['Class'].isin(['0','1'])]\n",
        "  return df.dropna()\n",
        "\n",
        "def split_data(x, y):\n",
        "  \"\"\"\n",
        "  Split into train test\n",
        "  \"\"\"\n",
        "  y_data = np.array([int(i) for i in y])\n",
        "  return train_test_split(x_data, y_data, test_size = 0.3)\n",
        "\n",
        "stopword = nltk.corpus.stopwords.words('english')\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "all_words = []\n",
        "def sanitize_text(text):\n",
        "  \"\"\"\n",
        "  Cleans tweet data by removing mentions, http links and retweet tags\n",
        "  \"\"\"\n",
        "  try:\n",
        "      # replace retweet tags\n",
        "      text = re.sub('^(RT @\\w+)', '', text)\n",
        "      # replace website URLs\n",
        "      text = re.sub('(https://)([A-Za-z0-9./]+)', '', text)\n",
        "      # replace mentions\n",
        "      text = re.sub('(@\\w+)', '', text)\n",
        "      text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
        "      text_rc = re.sub('[0-9]+', '', text_lc)\n",
        "      tokens = word_tokenize(text_rc)\n",
        "      text = [ps.stem(word) for word in tokens if word not in stopword]\n",
        "      all_words.extend(text)\n",
        "  except Exception as e:\n",
        "      print(e)\n",
        "  return text\n",
        "\n",
        "def clean_data(df):\n",
        "  \"\"\"\n",
        "  Creates new column with cleaned text and keeps only top 10000 most frequent words\n",
        "  \"\"\"\n",
        "  df['cleaned_text'] = df['Text'].apply(sanitize_text)\n",
        "  keys = dict(collections.Counter(all_words).most_common(vocab_size)).keys()\n",
        "\n",
        "  def keep_top(text):\n",
        "    text = [i for i in text if i in keys]\n",
        "    return \" \".join(text)\n",
        "\n",
        "\n",
        "  df['cleaned_text'] = df['cleaned_text'].apply(keep_top)\n",
        "  return df\n",
        "\n",
        "def encode_data(df, x):\n",
        "  \"\"\"\n",
        "  Integer encodes words in text to prepare data for embeddings\n",
        "  \"\"\"\n",
        "  encod_corp=[]\n",
        "  for i,doc in enumerate(df[x].tolist()):\n",
        "      encod_corp.append(one_hot(doc,vocab_size))\n",
        "  pad_corp=pad_sequences(encod_corp,maxlen=maxlen,padding='pre',value=0.0)\n",
        "  return pad_corp\n",
        "\n",
        "def create_model():\n",
        "  \"\"\"\n",
        "  Create model as mentioned in image\n",
        "  \"\"\"\n",
        "  model = Sequential()\n",
        "  model.add(layers.Input(shape=(maxlen,), dtype='float64'))\n",
        "  model.add(layers.Embedding(input_dim=vocab_size,output_dim=output_dim,input_length=maxlen))\n",
        "\n",
        "  model.add(layers.Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(50,32)))\n",
        "  model.add(layers.MaxPooling1D(pool_size=2))\n",
        "\n",
        "  model.add(layers.Bidirectional(layers.LSTM(256, return_sequences=True)))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Bidirectional(layers.LSTM(256)))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(1024, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(512, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  adam = Adam(learning_rate=0.0005)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def run_and_evaluate(epochs=1, batchsize=512):\n",
        "  \"\"\"\n",
        "  trains model and evaluates on given metrics\n",
        "  \"\"\"\n",
        "  model.fit(x_train, y_train, epochs=epochs, batch_size=batchsize, verbose=1)\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = [round(i[0]) for i in y_pred]\n",
        "  acc = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy score: {acc}\")\n",
        "  mcc = matthews_corrcoef(y_test, y_pred)\n",
        "  print(f\"Maththews correlation coefficient: {mcc}\")\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  print(f\"Confusion Matrix:\\n{cm}\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKtEWRcx_WLh"
      },
      "source": [
        "df = read_file(\"Colab Notebooks/data/CVAssignmentDataset.csv\")\n",
        "df_cleaned = clean_data(df)\n",
        "x_data = encode_data(df_cleaned, 'cleaned_text')\n",
        "x_train, x_test, y_train, y_test = split_data(x_data, df_cleaned['Class'].tolist())\n",
        "model = create_model()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMVy9poA_WLm",
        "outputId": "aa44c6ff-b2ca-42ea-9488-cb81df9957b6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 50, 32)            320000    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 50, 32)            1056      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 25, 32)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 25, 512)           591872    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 25, 512)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 512)               1574912   \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,538,465\n",
            "Trainable params: 3,538,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RJUXjnJ_WLp",
        "outputId": "c01135eb-c90d-4d27-e645-eb65fa327365"
      },
      "source": [
        "run_and_evaluate(12, 512)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "119/119 [==============================] - 43s 309ms/step - loss: 0.6697 - accuracy: 0.5543\n",
            "Epoch 2/10\n",
            "119/119 [==============================] - 37s 311ms/step - loss: 0.5062 - accuracy: 0.7506\n",
            "Epoch 3/10\n",
            "119/119 [==============================] - 37s 310ms/step - loss: 0.4640 - accuracy: 0.7753\n",
            "Epoch 4/10\n",
            "119/119 [==============================] - 37s 310ms/step - loss: 0.4458 - accuracy: 0.7853\n",
            "Epoch 5/10\n",
            "119/119 [==============================] - 37s 310ms/step - loss: 0.4333 - accuracy: 0.7924\n",
            "Epoch 6/10\n",
            "119/119 [==============================] - 37s 310ms/step - loss: 0.4186 - accuracy: 0.8015\n",
            "Epoch 7/10\n",
            "119/119 [==============================] - 37s 310ms/step - loss: 0.3948 - accuracy: 0.8139\n",
            "Epoch 8/10\n",
            "119/119 [==============================] - 37s 314ms/step - loss: 0.3743 - accuracy: 0.8230\n",
            "Epoch 9/10\n",
            "119/119 [==============================] - 37s 310ms/step - loss: 0.3852 - accuracy: 0.8204\n",
            "Epoch 10/10\n",
            "119/119 [==============================] - 37s 309ms/step - loss: 0.3297 - accuracy: 0.8481\n",
            "Accuracy score: 0.7185981956974323\n",
            "Maththews correlation coefficient: 0.4364677643987402\n",
            "Confusion Matrix:\n",
            "[[10041  3305]\n",
            " [ 3994  8598]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}